{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Dengue - ANN\n\n.. todo:: Full explanation\n\n.. todo:: Use column transformer.\n\n    ctf = ColumnTransformer(\n        [('gender', LabelBinarizer())]\n    )\n\n    data = ctf.fit_transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Libraries\nimport os\nimport sys\nimport calendar\nimport numpy as np\nimport pandas as pd\n#import modin.pandas as pd\n\n# Libraries imblearn\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\n\n# Libraries sklearn\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_auc_score\n\n# Import DataBlend\nfrom datablend.core.repair.correctors import oucru_dengue_interpretation_feature\nfrom datablend.core.repair.correctors import static_correction\n\n# ---------------------------------\n# Methods\n# ---------------------------------\ndef cvs_hos_split(data, **kwargs):\n    \"\"\"This method labels the dataframe hos and cvs sets.\n\n    Parameters\n    ----------\n    data: np.array or pd.DataFrame\n        The data to be divided into HOS/CVS.\n\n    Returns\n    -------\n    np.array:\n        The outcome is a numpy array with rows labelled as\n        cvs (cross-validation set) and hos (hold-out set).\n    \"\"\"\n    # Length\n    r, c = data.shape\n\n    # Create indexes to use for splitting\n    idxs = np.arange(r).reshape(-1, 1)\n\n    # Split in hos and training sets\n    cvs, hos = train_test_split(idxs, **kwargs)\n\n    # Create result\n    empty = np.array([None] * data.shape[0])\n    empty[cvs] = 'cvs'\n    empty[hos] = 'hos'\n\n    # Convert to series\n    if isinstance(data, pd.DataFrame):\n        empty = pd.Series(index=data.index, data=empty)\n\n    # Return\n    return empty\n\n# .. note: This is computationally expensive because it\n#          calls the same method (confusion_matrix) four\n#          times. But scorer functions need to be created\n#          for GridSearchCV.\n\ndef tp(y, y_pred, **kwargs):\n    \"\"\"Return the true positives\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n    return tp\n\ndef tn(y, y_pred, **kwargs):\n    \"\"\"Return the true negatives\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n    return tn\n\ndef fp(y, y_pred, **kwargs):\n    \"\"\"Return the false positives\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n    return fp\n\ndef fn(y, y_pred, **kwargs):\n    \"\"\"Return the false negatives\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n    return fn\n\n\n# ---------------------------------\n# Constants\n# ---------------------------------\n# The data filepath\npath = '../../resources/data/20210313-v0.0.8/'\npath+= 'combined/combined_tidy.csv'\n\n# Features\nfeatures = sorted(['age',\n                   'gender',\n                   'plt',\n                   'haematocrit_percent'])\n\n# Usecols\nusecols = ['date', 'study_no', 'dsource',\n    'day_from_admission', 'pcr_dengue_serotype',\n    'pcr_dengue_load', 'ns1_interpretation',\n    'igm_interpretation', 'igg_interpretation',\n    'serology_single_interpretation',\n    'serology_paired_interpretation']\nusecols+= features\n\n# ---------------------------------\n# Main\n# ---------------------------------\n\n# ---------\n# Load data\n# ---------\n# Read data\ndata = pd.read_csv(path,\n    low_memory=False,\n    #nrows=50000,\n    usecols=usecols,\n    parse_dates=['date'])\n\n# Reset index\ndata = data.reset_index()\n\n# Remove columns with all NaN\ndata = data.dropna(how='all', axis=1)\ndata = data.dropna(how='any', subset=features)\n\n# Add dengue interpretation\ndata['dengue_interpretation'] = \\\n    oucru_dengue_interpretation_feature(data,\n        pcr=True, ns1=False, igm=False, serology=False,\n        single_igm_igg=False, paired_igm_igg=False,\n        default=False)\n\n# Create outcome\ndata['outcome'] = \\\n    data.dengue_interpretation.astype(int)\n\n# Add month\ndata['month'] = data.date.dt.month\n\n# -----------\n# Format data\n# -----------\n\n# Keep only day_from_admission == 0 data\ndata = data[data.day_from_admission.isin([0, 1])]\n\n# Keep only certain months\n#data = data[data.month.isin([2, 3, 4])]\n\n# Drop any without interpretation\ndata = data[~data.dengue_interpretation.isna()]\n\n# Do this with sklearn column transformer\ndata.gender = data.gender.replace({'Male': 0, 'Female': 1})\n\n# -----------\n# Add splits\n# -----------\ndata['sets'] = cvs_hos_split(data, stratify=data.outcome)\n\n# Show information\nprint(\"\\n\\nData rows: %s\" % data.shape[0])\nprint(\"\\nby dsource:\")\nprint(data.dsource.value_counts())\nprint(\"\\nby outcome:\")\nprint(data.outcome.value_counts(dropna='False'))\nprint(\"\\nby sets:\")\nprint(data.sets.value_counts(dropna='False'))\nprint(\"\\n\")\n\n\n# ----------\n# Train\n# ----------\n# Estimator\nestimator = MLPClassifier()\n\nparam_grid = {\n    'ann__hidden_layer_sizes': [ (100, 100) ],\n    'ann__activation': ['relu'],\n    'ann__solver': ['adam'],\n    'ann__alpha': [0.001],\n    'ann__batch_size': ['auto'],\n    'ann__learning_rate': ['constant'],\n    'ann__learning_rate_init': [0.001],\n    'ann__power_t': [0.5],\n    'ann__max_iter': [10000],\n    'ann__tol': [1e-4],\n    'ann__warm_start': [False],\n    'ann__momentum': [0.9],\n}\n\n# Scoring\nscoring = {\n    'aucroc': 'roc_auc',\n    'sensitivity': make_scorer(recall_score),\n    'specificity': make_scorer(recall_score, pos_label=0),\n    #'tp': make_scorer(tp),\n    #'tn': make_scorer(tn),\n    #'fp': make_scorer(fp),\n    #'fn': make_scorer(fn),\n}\n\n# Create pipeline\npipe = Pipeline(steps=[#('smt', SMOTE(random_state=42)),\n                       ('std', StandardScaler()),\n                       ('ann', estimator)],\n                memory='./outputs',\n                verbose=True)\n\n# Create k-folds\nkf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# Create grid search\ngrid = GridSearchCV(pipe, cv=kf, scoring=scoring,\n    param_grid=param_grid, return_train_score=True,\n    refit='aucroc')\n\n# Define\nfeatures = features\ntarget = 'outcome'\n\n# Get train data\ntrain = data[data.sets == 'cvs']\ntrain = train[features + [target]]\n#train = train.dropna(how='any') # done already\n\n# Get X and y\nX = train[features].to_numpy()\ny = train[target].to_numpy()\n\n# Fit\ngrid.fit(X, y);\n\n# ----------------\n# Show scores\n# ----------------\n# Show results\nresults = pd.DataFrame(grid.cv_results_)\n\n#print(\"\\nResult columns:\")\n#print(results.columns.values)\nprint(\"\\n\\nGrid Search ALL scores (CVS):\")\nprint(results.round(decimals=3).T)\n\n# Select columns\ncolumns = [c for c in results.columns if 'param_' in c]\ncolumns+= [c for c in results.columns if 'mean_' in c]\ncolumns = sorted(columns)\n\n# Show\nprint(\"\\nGrid Search MEAN scores (CVS):\")\nprint(results[columns].round(decimals=3).T)\n\n# -------------------\n# Best estimator\n# -------------------\n# .. note: It is possible to evaluate the estimator\n#          only in HOS. In addition, we would like to\n#          see how the predictions and metrics vary\n#          according to the seasonality.\n# Get best estimator\nbest_estimator = grid.best_estimator_\n\n# -----------------\n# Evaluation in HOS\n# -----------------\n# Evaluate best estimator on HOS\nhos = data[data.sets == 'hos']\n\n# Get X and y\nX = hos[features].to_numpy()\ny = hos[target].to_numpy()\n\n# Do predictions\ny_pred = best_estimator.predict(X)\ny_score = best_estimator.predict_proba(X)\n\n# Scores\naucroc = roc_auc_score(y, y_score[:, 1])\nsensitivity = recall_score(y, y_pred)\nspecificity = recall_score(y, y_pred, pos_label=0)\n\n# Create series\nseries = pd.Series(\\\n    index=['AUCROC', 'Sensitivity', 'Specificity'],\n    data=[aucroc, sensitivity, specificity])\n\n# Show\nprint(\"\\nBest estimator HOS scores:\")\nprint(series.round(decimals=3))\n\n# --------------------------------\n# Evaluation of seasonality effect\n# --------------------------------\n# Get X and y\nX = data[features].to_numpy()\ny = data[target].to_numpy()\n\n# Add columns to data\ndata['y_pred'] = best_estimator.predict(X)\ndata['y_score'] = best_estimator.predict_proba(X)[:, 1]\n\n#\ndef _aucroc(x):\n    try:\n        return roc_auc_score(x.outcome, x.y_score)\n    except:\n        return None\n\ndef _sens(x):\n    try:\n        return recall_score(x.outcome, x.y_pred)\n    except:\n        return None\n\ndef _spec(x):\n    try:\n        return recall_score(x.outcome, x.y_pred, pos_label=0)\n    except:\n        return None\n\ndef prevalence(x):\n    return (np.sum(x) / len(x)) * 100\n\n# Outputs\naucroc = data.groupby('month').apply(_aucroc)\nsensitivity = data.groupby('month').apply(_sens)\nspecificity = data.groupby('month').apply(_spec)\nprevalence = data.groupby('month').outcome.apply(prevalence)\n\n# Scores\nscores = pd.DataFrame()\nscores['aucroc'] = aucroc * 100\nscores['sens'] = sensitivity * 100\nscores['spec'] = specificity * 100\nscores['prevalence'] = prevalence\nscores['n'] = data.groupby('month').study_no.count()\n#scores['sens_prev_ratio'] = scores.sens / scores.prevalence\n#scores['spec_prev_ratio'] = scores.spec / scores.prevalence\n#scores['spec_prev_ratio'] = scores.spec / scores.prevalence\n#scores['spec_n_ratio'] = scores.spec / scores.n\nscores = scores.round(decimals=3)\n\nprint(scores)\n\n# Add legible labels\nscores.index = \\\n     [calendar.month_abbr[x] for x in scores.index]\n\n# Create stacked version (seaborn)\nscores_stacked = scores.stack().reset_index()\nscores_stacked.columns = ['month', 'metric', 'result']\n\n# Show\nprint(\"\\nMonthly scores:\")\nprint(scores)\n\nprint(\"\\nMonthly scores (stacked):\")\nprint(scores_stacked)\n\nprint(\"\\nCorrelation with prevalence (pearson):\")\nprint(scores.corr()[['prevalence', 'n']])\nprint(\"\\nCorrelation with prevalence (spearman):\")\nprint(scores.corr(method='spearman')[['prevalence', 'n']])\n\n# ------------------------------------------------\n# Plot\n# ------------------------------------------------\n# Libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Seaborn\nsns.set_theme(style=\"whitegrid\")\n\n\n# --------------\n# Plot FacetGrid\n# --------------\n\"\"\"\nsns.set_color_codes(\"muted\")\nsns.despine(left=True, bottom=True)\n\n# Create facet grid\ng = sns.FacetGrid(scores_stacked,\n    col=\"metric\", col_wrap=3, sharey=False,\n    aspect=1.5)\n\n# Plot sns plots\ng.map_dataframe(sns.barplot, x=\"month\",\n    y=\"result\", linewidth=0.76)\n\"\"\"\n\n# ---------------\n# Plot main\n# ---------------\n# Colors\ncolors = ['b', 'g', 'r', 'b']\n\n# Initialize the figure\nf, axes = plt.subplots(1, 4, figsize=(12, 2.5), sharey=True)\naxes = axes.flatten()\n\n# Plot\nfor i, c in enumerate(['aucroc', 'sens', 'spec', 'prevalence']):\n\n    # Plot barplot\n    sns.despine(left=True, bottom=True)\n    sns.barplot(x=scores.index,\n             y=scores[c],\n             label=c,\n             color=colors[i],\n             ax=axes[i],\n             linewidth=0.75)\n\n    # Add a legend and informative axis label\n    axes[i].legend(ncol=2, loc=\"lower right\", frameon=True)\n    axes[i].set(xlabel=\"\", ylabel=\"\",\n        title=\"%s in HTD by month\" % c)\n\n# Tight layout\nplt.tight_layout()\n\n\n\"\"\"\n# --------------------\n# Plot others\n# --------------------\n# Initialize the figure\nf, axes = plt.subplots(1, 4, figsize=(12, 2.5))\naxes = axes.flatten()\n\n# Plot\nfor i, c in enumerate(['aucroc',\n                       'sens',\n                       'spec']):\n\n    # Plot barplot\n    sns.despine(left=True, bottom=True)\n    sns.barplot(x=scores.index,\n             y=scores[c] / scores.prevalence,\n             label=c,\n             color='b',\n             ax=axes[i],\n             linewidth=0.75)\n\n    # Add a legend and informative axis label\n    axes[i].legend(ncol=2, loc=\"lower right\", frameon=True)\n    axes[i].set(xlabel=\"\", ylabel=\"\",\n        title=\"%s in HTD by month\" % c)\n\nplt.tight_layout()\n\"\"\"\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}