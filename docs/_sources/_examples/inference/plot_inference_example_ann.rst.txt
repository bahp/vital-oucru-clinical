
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_examples\inference\plot_inference_example_ann.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download__examples_inference_plot_inference_example_ann.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__examples_inference_plot_inference_example_ann.py:


Dengue - ANN
=============

.. todo:: Full explanation

.. todo:: Use column transformer.

    ctf = ColumnTransformer(
        [('gender', LabelBinarizer())]
    )

    data = ctf.fit_transform(data)

.. GENERATED FROM PYTHON SOURCE LINES 16-487



.. image:: /_examples/inference/images/sphx_glr_plot_inference_example_ann_001.png
    :alt: aucroc in HTD by month, sens in HTD by month, spec in HTD by month, prevalence in HTD by month
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Applying... oucru_dengue_interpretation_feature.


    Data rows: 11967

    by dsource:
    md       5971
    df       1661
    fl       1338
    42dx     1195
    13dx      917
    06dx      363
    01nva     221
    dr        126
    d001      110
    32dx       65
    Name: dsource, dtype: int64

    by outcome:
    0    6271
    1    5696
    Name: outcome, dtype: int64

    by sets:
    cvs    8975
    hos    2992
    Name: sets, dtype: int64


    [Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s
    [Pipeline] ............... (step 2 of 2) Processing ann, total=   6.7s
    [Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s
    [Pipeline] ............... (step 2 of 2) Processing ann, total=   8.4s
    [Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s
    [Pipeline] ............... (step 2 of 2) Processing ann, total=   5.9s
    [Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s
    [Pipeline] ............... (step 2 of 2) Processing ann, total=   5.1s
    [Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s
    [Pipeline] ............... (step 2 of 2) Processing ann, total=   7.2s
    [Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s
    [Pipeline] ............... (step 2 of 2) Processing ann, total=   5.4s


    Grid Search ALL scores (CVS):
                                  0
    mean_fit_time             6.688
    std_fit_time              1.126
    mean_score_time           0.009
    std_score_time            0.001
    param_ann__activation      relu
    ...                         ...
    split2_train_specificity  0.743
    split3_train_specificity  0.704
    split4_train_specificity   0.69
    mean_train_specificity    0.699
    std_train_specificity     0.028

    [62 rows x 1 columns]

    Grid Search MEAN scores (CVS):
                                            0
    mean_fit_time                       6.688
    mean_score_time                     0.009
    mean_test_aucroc                    0.761
    mean_test_sensitivity               0.661
    mean_test_specificity               0.694
    mean_train_aucroc                   0.771
    mean_train_sensitivity              0.667
    mean_train_specificity              0.699
    param_ann__activation                relu
    param_ann__alpha                    0.001
    param_ann__batch_size                auto
    param_ann__hidden_layer_sizes  (100, 100)
    param_ann__learning_rate         constant
    param_ann__learning_rate_init       0.001
    param_ann__max_iter                 10000
    param_ann__momentum                   0.9
    param_ann__power_t                    0.5
    param_ann__solver                    adam
    param_ann__tol                     0.0001
    param_ann__warm_start               False

    Best estimator HOS scores:
    AUCROC         0.755
    Sensitivity    0.584
    Specificity    0.742
    dtype: float64
           aucroc    sens    spec  prevalence     n
    month                                          
    1      78.224  62.893  76.215      44.852   709
    2      72.354  58.333  73.611      29.412   408
    3      76.798  61.433  73.515      42.037   697
    4      71.104  52.047  78.497      30.700   557
    5      74.377  57.273  75.730      33.083   665
    6      79.715  63.613  79.630      37.752  1041
    7      75.664  58.942  74.488      46.730  1376
    8      78.618  56.469  79.412      56.212  1320
    9      78.963  58.916  77.487      55.024  1274
    10     75.055  63.402  69.949      56.850  1365
    11     73.851  59.578  70.776      50.227  1320
    12     75.569  60.366  74.439      53.117  1235

    Monthly scores:
         aucroc    sens    spec  prevalence     n
    Jan  78.224  62.893  76.215      44.852   709
    Feb  72.354  58.333  73.611      29.412   408
    Mar  76.798  61.433  73.515      42.037   697
    Apr  71.104  52.047  78.497      30.700   557
    May  74.377  57.273  75.730      33.083   665
    Jun  79.715  63.613  79.630      37.752  1041
    Jul  75.664  58.942  74.488      46.730  1376
    Aug  78.618  56.469  79.412      56.212  1320
    Sep  78.963  58.916  77.487      55.024  1274
    Oct  75.055  63.402  69.949      56.850  1365
    Nov  73.851  59.578  70.776      50.227  1320
    Dec  75.569  60.366  74.439      53.117  1235

    Monthly scores (stacked):
       month      metric    result
    0    Jan      aucroc    78.224
    1    Jan        sens    62.893
    2    Jan        spec    76.215
    3    Jan  prevalence    44.852
    4    Jan           n   709.000
    5    Feb      aucroc    72.354
    6    Feb        sens    58.333
    7    Feb        spec    73.611
    8    Feb  prevalence    29.412
    9    Feb           n   408.000
    10   Mar      aucroc    76.798
    11   Mar        sens    61.433
    12   Mar        spec    73.515
    13   Mar  prevalence    42.037
    14   Mar           n   697.000
    15   Apr      aucroc    71.104
    16   Apr        sens    52.047
    17   Apr        spec    78.497
    18   Apr  prevalence    30.700
    19   Apr           n   557.000
    20   May      aucroc    74.377
    21   May        sens    57.273
    22   May        spec    75.730
    23   May  prevalence    33.083
    24   May           n   665.000
    25   Jun      aucroc    79.715
    26   Jun        sens    63.613
    27   Jun        spec    79.630
    28   Jun  prevalence    37.752
    29   Jun           n  1041.000
    30   Jul      aucroc    75.664
    31   Jul        sens    58.942
    32   Jul        spec    74.488
    33   Jul  prevalence    46.730
    34   Jul           n  1376.000
    35   Aug      aucroc    78.618
    36   Aug        sens    56.469
    37   Aug        spec    79.412
    38   Aug  prevalence    56.212
    39   Aug           n  1320.000
    40   Sep      aucroc    78.963
    41   Sep        sens    58.916
    42   Sep        spec    77.487
    43   Sep  prevalence    55.024
    44   Sep           n  1274.000
    45   Oct      aucroc    75.055
    46   Oct        sens    63.402
    47   Oct        spec    69.949
    48   Oct  prevalence    56.850
    49   Oct           n  1365.000
    50   Nov      aucroc    73.851
    51   Nov        sens    59.578
    52   Nov        spec    70.776
    53   Nov  prevalence    50.227
    54   Nov           n  1320.000
    55   Dec      aucroc    75.569
    56   Dec        sens    60.366
    57   Dec        spec    74.439
    58   Dec  prevalence    53.117
    59   Dec           n  1235.000

    Correlation with prevalence (pearson):
                prevalence         n
    aucroc        0.496461  0.418802
    sens          0.350345  0.276866
    spec         -0.225155 -0.167932
    prevalence    1.000000  0.874446
    n             0.874446  1.000000

    Correlation with prevalence (spearman):
                prevalence         n
    aucroc        0.405594  0.353766
    sens          0.244755  0.283713
    spec         -0.174825 -0.171629
    prevalence    1.000000  0.844134
    n             0.844134  1.000000






|

.. code-block:: default
   :lineno-start: 18



    # Libraries
    import os
    import sys
    import calendar
    import numpy as np
    import pandas as pd
    #import modin.pandas as pd

    # Libraries imblearn
    from imblearn.pipeline import Pipeline
    from imblearn.over_sampling import SMOTE

    # Libraries sklearn
    from sklearn.compose import ColumnTransformer
    from sklearn.model_selection import train_test_split
    from sklearn.model_selection import StratifiedKFold
    from sklearn.model_selection import GridSearchCV
    from sklearn.preprocessing import StandardScaler
    from sklearn.preprocessing import LabelBinarizer
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.neural_network import MLPClassifier
    from sklearn.metrics import make_scorer
    from sklearn.metrics import confusion_matrix
    from sklearn.metrics import recall_score
    from sklearn.metrics import roc_auc_score

    # Import DataBlend
    from datablend.core.repair.correctors import oucru_dengue_interpretation_feature
    from datablend.core.repair.correctors import static_correction

    # ---------------------------------
    # Methods
    # ---------------------------------
    def cvs_hos_split(data, **kwargs):
        """This method labels the dataframe hos and cvs sets.

        Parameters
        ----------
        data: np.array or pd.DataFrame
            The data to be divided into HOS/CVS.

        Returns
        -------
        np.array:
            The outcome is a numpy array with rows labelled as
            cvs (cross-validation set) and hos (hold-out set).
        """
        # Length
        r, c = data.shape

        # Create indexes to use for splitting
        idxs = np.arange(r).reshape(-1, 1)

        # Split in hos and training sets
        cvs, hos = train_test_split(idxs, **kwargs)

        # Create result
        empty = np.array([None] * data.shape[0])
        empty[cvs] = 'cvs'
        empty[hos] = 'hos'

        # Convert to series
        if isinstance(data, pd.DataFrame):
            empty = pd.Series(index=data.index, data=empty)

        # Return
        return empty

    # .. note: This is computationally expensive because it
    #          calls the same method (confusion_matrix) four
    #          times. But scorer functions need to be created
    #          for GridSearchCV.

    def tp(y, y_pred, **kwargs):
        """Return the true positives"""
        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()
        return tp

    def tn(y, y_pred, **kwargs):
        """Return the true negatives"""
        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()
        return tn

    def fp(y, y_pred, **kwargs):
        """Return the false positives"""
        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()
        return fp

    def fn(y, y_pred, **kwargs):
        """Return the false negatives"""
        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()
        return fn


    # ---------------------------------
    # Constants
    # ---------------------------------
    # The data filepath
    path = '../../resources/data/20210313-v0.0.8/'
    path+= 'combined/combined_tidy.csv'

    # Features
    features = sorted(['age',
                       'gender',
                       'plt',
                       'haematocrit_percent'])

    # Usecols
    usecols = ['date', 'study_no', 'dsource',
        'day_from_admission', 'pcr_dengue_serotype',
        'pcr_dengue_load', 'ns1_interpretation',
        'igm_interpretation', 'igg_interpretation',
        'serology_single_interpretation',
        'serology_paired_interpretation']
    usecols+= features

    # ---------------------------------
    # Main
    # ---------------------------------

    # ---------
    # Load data
    # ---------
    # Read data
    data = pd.read_csv(path,
        low_memory=False,
        #nrows=50000,
        usecols=usecols,
        parse_dates=['date'])

    # Reset index
    data = data.reset_index()

    # Remove columns with all NaN
    data = data.dropna(how='all', axis=1)
    data = data.dropna(how='any', subset=features)

    # Add dengue interpretation
    data['dengue_interpretation'] = \
        oucru_dengue_interpretation_feature(data,
            pcr=True, ns1=False, igm=False, serology=False,
            single_igm_igg=False, paired_igm_igg=False,
            default=False)

    # Create outcome
    data['outcome'] = \
        data.dengue_interpretation.astype(int)

    # Add month
    data['month'] = data.date.dt.month

    # -----------
    # Format data
    # -----------

    # Keep only day_from_admission == 0 data
    data = data[data.day_from_admission.isin([0, 1])]

    # Keep only certain months
    #data = data[data.month.isin([2, 3, 4])]

    # Drop any without interpretation
    data = data[~data.dengue_interpretation.isna()]

    # Do this with sklearn column transformer
    data.gender = data.gender.replace({'Male': 0, 'Female': 1})

    # -----------
    # Add splits
    # -----------
    data['sets'] = cvs_hos_split(data, stratify=data.outcome)

    # Show information
    print("\n\nData rows: %s" % data.shape[0])
    print("\nby dsource:")
    print(data.dsource.value_counts())
    print("\nby outcome:")
    print(data.outcome.value_counts(dropna='False'))
    print("\nby sets:")
    print(data.sets.value_counts(dropna='False'))
    print("\n")


    # ----------
    # Train
    # ----------
    # Estimator
    estimator = MLPClassifier()

    param_grid = {
        'ann__hidden_layer_sizes': [ (100, 100) ],
        'ann__activation': ['relu'],
        'ann__solver': ['adam'],
        'ann__alpha': [0.001],
        'ann__batch_size': ['auto'],
        'ann__learning_rate': ['constant'],
        'ann__learning_rate_init': [0.001],
        'ann__power_t': [0.5],
        'ann__max_iter': [10000],
        'ann__tol': [1e-4],
        'ann__warm_start': [False],
        'ann__momentum': [0.9],
    }

    # Scoring
    scoring = {
        'aucroc': 'roc_auc',
        'sensitivity': make_scorer(recall_score),
        'specificity': make_scorer(recall_score, pos_label=0),
        #'tp': make_scorer(tp),
        #'tn': make_scorer(tn),
        #'fp': make_scorer(fp),
        #'fn': make_scorer(fn),
    }

    # Create pipeline
    pipe = Pipeline(steps=[#('smt', SMOTE(random_state=42)),
                           ('std', StandardScaler()),
                           ('ann', estimator)],
                    memory='./outputs',
                    verbose=True)

    # Create k-folds
    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)

    # Create grid search
    grid = GridSearchCV(pipe, cv=kf, scoring=scoring,
        param_grid=param_grid, return_train_score=True,
        refit='aucroc')

    # Define
    features = features
    target = 'outcome'

    # Get train data
    train = data[data.sets == 'cvs']
    train = train[features + [target]]
    #train = train.dropna(how='any') # done already

    # Get X and y
    X = train[features].to_numpy()
    y = train[target].to_numpy()

    # Fit
    grid.fit(X, y);

    # ----------------
    # Show scores
    # ----------------
    # Show results
    results = pd.DataFrame(grid.cv_results_)

    #print("\nResult columns:")
    #print(results.columns.values)
    print("\n\nGrid Search ALL scores (CVS):")
    print(results.round(decimals=3).T)

    # Select columns
    columns = [c for c in results.columns if 'param_' in c]
    columns+= [c for c in results.columns if 'mean_' in c]
    columns = sorted(columns)

    # Show
    print("\nGrid Search MEAN scores (CVS):")
    print(results[columns].round(decimals=3).T)

    # -------------------
    # Best estimator
    # -------------------
    # .. note: It is possible to evaluate the estimator
    #          only in HOS. In addition, we would like to
    #          see how the predictions and metrics vary
    #          according to the seasonality.
    # Get best estimator
    best_estimator = grid.best_estimator_

    # -----------------
    # Evaluation in HOS
    # -----------------
    # Evaluate best estimator on HOS
    hos = data[data.sets == 'hos']

    # Get X and y
    X = hos[features].to_numpy()
    y = hos[target].to_numpy()

    # Do predictions
    y_pred = best_estimator.predict(X)
    y_score = best_estimator.predict_proba(X)

    # Scores
    aucroc = roc_auc_score(y, y_score[:, 1])
    sensitivity = recall_score(y, y_pred)
    specificity = recall_score(y, y_pred, pos_label=0)

    # Create series
    series = pd.Series(\
        index=['AUCROC', 'Sensitivity', 'Specificity'],
        data=[aucroc, sensitivity, specificity])

    # Show
    print("\nBest estimator HOS scores:")
    print(series.round(decimals=3))

    # --------------------------------
    # Evaluation of seasonality effect
    # --------------------------------
    # Get X and y
    X = data[features].to_numpy()
    y = data[target].to_numpy()

    # Add columns to data
    data['y_pred'] = best_estimator.predict(X)
    data['y_score'] = best_estimator.predict_proba(X)[:, 1]

    #
    def _aucroc(x):
        try:
            return roc_auc_score(x.outcome, x.y_score)
        except:
            return None

    def _sens(x):
        try:
            return recall_score(x.outcome, x.y_pred)
        except:
            return None

    def _spec(x):
        try:
            return recall_score(x.outcome, x.y_pred, pos_label=0)
        except:
            return None

    def prevalence(x):
        return (np.sum(x) / len(x)) * 100

    # Outputs
    aucroc = data.groupby('month').apply(_aucroc)
    sensitivity = data.groupby('month').apply(_sens)
    specificity = data.groupby('month').apply(_spec)
    prevalence = data.groupby('month').outcome.apply(prevalence)

    # Scores
    scores = pd.DataFrame()
    scores['aucroc'] = aucroc * 100
    scores['sens'] = sensitivity * 100
    scores['spec'] = specificity * 100
    scores['prevalence'] = prevalence
    scores['n'] = data.groupby('month').study_no.count()
    #scores['sens_prev_ratio'] = scores.sens / scores.prevalence
    #scores['spec_prev_ratio'] = scores.spec / scores.prevalence
    #scores['spec_prev_ratio'] = scores.spec / scores.prevalence
    #scores['spec_n_ratio'] = scores.spec / scores.n
    scores = scores.round(decimals=3)

    print(scores)

    # Add legible labels
    scores.index = \
         [calendar.month_abbr[x] for x in scores.index]

    # Create stacked version (seaborn)
    scores_stacked = scores.stack().reset_index()
    scores_stacked.columns = ['month', 'metric', 'result']

    # Show
    print("\nMonthly scores:")
    print(scores)

    print("\nMonthly scores (stacked):")
    print(scores_stacked)

    print("\nCorrelation with prevalence (pearson):")
    print(scores.corr()[['prevalence', 'n']])
    print("\nCorrelation with prevalence (spearman):")
    print(scores.corr(method='spearman')[['prevalence', 'n']])

    # ------------------------------------------------
    # Plot
    # ------------------------------------------------
    # Libraries
    import seaborn as sns
    import matplotlib.pyplot as plt

    # Seaborn
    sns.set_theme(style="whitegrid")


    # --------------
    # Plot FacetGrid
    # --------------
    """
    sns.set_color_codes("muted")
    sns.despine(left=True, bottom=True)

    # Create facet grid
    g = sns.FacetGrid(scores_stacked,
        col="metric", col_wrap=3, sharey=False,
        aspect=1.5)

    # Plot sns plots
    g.map_dataframe(sns.barplot, x="month",
        y="result", linewidth=0.76)
    """

    # ---------------
    # Plot main
    # ---------------
    # Colors
    colors = ['b', 'g', 'r', 'b']

    # Initialize the figure
    f, axes = plt.subplots(1, 4, figsize=(12, 2.5), sharey=True)
    axes = axes.flatten()

    # Plot
    for i, c in enumerate(['aucroc', 'sens', 'spec', 'prevalence']):

        # Plot barplot
        sns.despine(left=True, bottom=True)
        sns.barplot(x=scores.index,
                 y=scores[c],
                 label=c,
                 color=colors[i],
                 ax=axes[i],
                 linewidth=0.75)

        # Add a legend and informative axis label
        axes[i].legend(ncol=2, loc="lower right", frameon=True)
        axes[i].set(xlabel="", ylabel="",
            title="%s in HTD by month" % c)

    # Tight layout
    plt.tight_layout()


    """
    # --------------------
    # Plot others
    # --------------------
    # Initialize the figure
    f, axes = plt.subplots(1, 4, figsize=(12, 2.5))
    axes = axes.flatten()

    # Plot
    for i, c in enumerate(['aucroc',
                           'sens',
                           'spec']):

        # Plot barplot
        sns.despine(left=True, bottom=True)
        sns.barplot(x=scores.index,
                 y=scores[c] / scores.prevalence,
                 label=c,
                 color='b',
                 ax=axes[i],
                 linewidth=0.75)

        # Add a legend and informative axis label
        axes[i].legend(ncol=2, loc="lower right", frameon=True)
        axes[i].set(xlabel="", ylabel="",
            title="%s in HTD by month" % c)

    plt.tight_layout()
    """

    plt.show()


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  42.183 seconds)


.. _sphx_glr_download__examples_inference_plot_inference_example_ann.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_inference_example_ann.py <plot_inference_example_ann.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_inference_example_ann.ipynb <plot_inference_example_ann.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
